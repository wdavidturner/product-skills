---
title: Only Survey Users Who Experienced Core Value
impact: CRITICAL
tags: survey-design, sampling, methodology
---

## Only Survey Users Who Experienced Core Value

Surveying all users dilutes your signal. Users who signed up but never activated will say "not disappointed" because they never experienced what makes you valuable.

**Incorrect (surveying everyone):**

> **Survey sample:** All 500 users who signed up in the last month
>
> **Results:**
> - Very disappointed: 18%
> - Somewhat disappointed: 27%
> - Not disappointed: 55%
>
> **Team's conclusion:** "Our PMF is terrible. We need to pivot."

But wait - 60% of those surveyed signed up and never completed onboarding. They literally never experienced the product.

**Correct (surveying activated users):**

> **Survey sample:** 200 users who completed onboarding AND used the core feature at least 3 times in the past month
>
> **Results:**
> - Very disappointed: 38%
> - Somewhat disappointed: 35%
> - Not disappointed: 27%
>
> **Team's conclusion:** "Our activated users are close to 40%. We have a PMF problem AND an activation problem - they're separate issues to solve."

Now you've separated two distinct problems: (1) Does the product deliver value to people who use it? (2) Are people successfully getting to the value?

**Why it matters:**

Mixing activated and unactivated users conflates product value with onboarding effectiveness. You'll make roadmap decisions based on noise. Survey users who've actually experienced what you're asking them to evaluate.
