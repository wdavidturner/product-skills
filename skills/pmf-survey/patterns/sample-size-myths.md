---
title: 40-50 Responses Is Enough
impact: HIGH
tags: sample-size, methodology, statistics
---

## 40-50 Responses Is Enough

Teams delay running PMF surveys waiting for "statistical significance." You're looking for patterns, not p-values. Directional insight from 40 responses beats perfect data never collected.

**Incorrect (waiting for statistical perfection):**

> **PM:** "We only have 80 active users. Let's wait until we have 500 so the survey is statistically significant."
>
> *Six months later:* Still waiting. Making product decisions based on gut feeling. No idea if they're improving PMF or making it worse.

Statistical significance matters for A/B tests where you need to detect small differences. PMF surveys are looking for big patterns.

**Correct (acting on directional data):**

> **PM:** "We have 80 active users. Let's survey all of them."
>
> **Results (52 responses):**
> - Very disappointed: 12 (23%)
> - Somewhat disappointed: 22 (42%)
> - Not disappointed: 18 (35%)
>
> **Insight:** "We're below 40%, but we have a lot of fence-sitters. Let's analyze what's holding them back."
>
> *Three months later:* Re-run survey. Score moved from 23% to 34%. "We're heading the right direction. Let's keep iterating."

You learned something actionable. You can measure progress. You're making informed decisions.

**Why it matters:**

The confidence interval on 50 responses might be +/- 10 points. But knowing "we're somewhere between 25-35%" is infinitely more useful than knowing nothing. Ship the survey, learn, iterate. Precision comes from repetition, not sample size.
