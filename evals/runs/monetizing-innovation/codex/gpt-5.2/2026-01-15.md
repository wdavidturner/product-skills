# Skill Eval Feedback

skill: monetizing-innovation
agent: codex
model: gpt-5.2
date: 2026-01-15
prompt-set: evals/prompts/skill-prompts.yaml

## Prompt Results

| Prompt ID | Triggered? | Helpful? (1-5) | Too Much Context? | Missing Context? | Notes |
|-----------|------------|----------------|-------------------|------------------|-------|
| minimal |  |  |  |  |  |
| context |  |  |  |  |  |

## Overall

- Trigger quality:
- Usefulness:
- Over/under-trigger risk:
- Suggested description tweaks:
- Suggested SKILL.md tweaks:

## Raw Output

### minimal

Prompt:

```
How do I figure out pricing for a new product? Walk me through the process.
```

Response:

```
Here’s a practical end-to-end process you can use to price a new product (works for SaaS, APIs, and most B2B/B2C software).

1) Define the pricing “job”
- Goal: maximize revenue, adoption, profit, or speed-to-market (pick one primary).
- Constraints: brand positioning (premium vs value), sales motion (self-serve vs sales-led), contract norms, regulatory/market limits.
- Success metrics: conversion rate, ARPA/ARPU, retention, gross margin, CAC payback.

2) Pin down who you’re pricing for (segmentation)
- Identify 2–4 core segments that differ in willingness-to-pay (WTP) and usage (e.g., SMB vs mid-market; hobbyist vs pro).
- Write a simple segment table: segment, main use case, value drivers, budget owner, alternatives, expected usage range.

3) Define what customers are actually paying for (value metric)
Pick the “meter” that best tracks value and scales with customer outcomes:
- Subscription: per seat, per workspace, per location.
- Usage-based: per API call, per GB, per transaction, per automations run.
- Hybrid: base subscription + usage overages.
Rules of thumb:
- The metric should be understandable, controllable by the buyer, and correlate with value.
- Avoid metrics that spike unpredictably unless you add caps/commitments.

4) Quantify value and anchor ranges (value-based pricing)
- Estimate economic value: time saved, revenue gained, risk reduced, cost avoided.
- Convert to an ROI story: “We create ~$X/month of value; price captures ~10–30% of that” (common in B2B, varies widely).
- Output: a believable WTP range per segment (not a single number yet).

5) Do market reality checks (competition + alternatives)
- Map alternatives (including “do nothing” and internal tools), not just direct competitors.
- Note price model, packaging, and the “gotchas” (limits, overages, required add-ons).
- Decide your positioning: cheaper, parity, or premium—and why you win.

6) Build your floors: unit economics and deal economics
You need a hard floor to avoid pricing that can’t work:
- Variable costs (COGS): infra, support, onboarding, compliance, third-party fees.
- Gross margin target (common SaaS: high; usage-heavy products: lower but still planned).
- Sales costs: if sales-led, ensure ACV supports CAC payback targets.
- Output: minimum viable price (by segment/model) and minimum contract size if applicable.

7) Design packaging (tiers) before picking the final numbers
- Create 3 tiers that match segments/use cases (e.g., Starter / Pro / Enterprise).
- Differentiate tiers by: limits, features, compliance, admin controls, SLA, support, integrations.
- Make upgrades feel natural as value/complexity grows; avoid “random” feature gating.

8) Set initial price points (list price, not just “what we’ll discount to”)
A simple way to land on numbers:
- Choose an “intended” tier for your core segment (the one most should buy).
- Price it inside your WTP range and above your economic floor.
- Use price architecture to guide choices:
  - 3 tiers with ~2–3× jumps (Starter → Pro → Enterprise) is common.
  - Ensure Starter is viable but intentionally constrained (to prevent over-delivery).
- Decide discount policy early (annual prepay, volume, startups, nonprofit) and set guardrails.

9) Validate with lightweight research + tests (before locking in)
Combine qualitative + quantitative:
- Pricing interviews (10–20): test value metric, packaging clarity, and “would you buy at $X?” with context.
- Van Westendorp (good for simpler B2C/self-serve): “too cheap/cheap/expensive/too expensive.”
- Gabor-Granger (good for B2B): present price points and measure purchase intent.
- Offer tests (best if you can): landing page A/B, checkout experiments, sales quoting experiments.
Output: where resistance appears (metric confusion, tier mismatch, price too high/low) and updated ranges.

10) Launch with guardrails and a plan to iterate
- Publish pricing with clear limits, examples, and a calculator (especially for usage-based).
- Add protections: free trial design, caps/alerts, grace thresholds, annual commit options.
- Set review cadence (e.g., monthly for early stage) and watch:
  - Conversion by segment, expansion, churn, gross margin, discounting behavior, support load.
- Iterate carefully: packaging changes often outperform pure price changes.

If you tell me (a) B2B vs B2C, (b) sales-led vs self-serve, (c) what the product replaces, and (d) your likely value metric, I can help you produce a first-pass tier/package + price range and a concrete validation plan.

[stderr]
OpenAI Codex v0.80.0 (research preview)
--------
workdir: /Users/davidturner/Code/Playground/ProductSkills
model: gpt-5.2
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019bc219-beba-7441-8116-f1974e81804e
--------
user
How do I figure out pricing for a new product? Walk me through the process.
mcp startup: no servers


thinking
**Outlining the pricing process**

The user is asking about the product pricing process, but there are no relevant repo tasks or skills triggered for this. I need to answer them concisely yet provide a step-by-step guide. 

First, I'll mention frameworks like value-based and competitive pricing, segmentation, and packaging. I think it would be helpful to clarify the customer and their value, research willingness to pay, and perform a competitive scan. 

Then I'll guide them on choosing a pricing model, packaging tiers, setting an initial price, and validating through testing before launching. This should be structured but not too lengthy!
thinking
**Creating a pricing strategy**

I want to outline a structured pricing strategy with clear steps. First, I’ll define the objective. Next, I’ll identify the customer segment and their jobs. Then, I’ll establish the value metric and quantify that value, including ROI. I'll also collect market data and compute unit economics. 

After that, it’s about choosing the pricing model and packaging, setting the list price, deciding on discounts, and validating the approach. Finally, I’ll roll it out and iterate as necessary. I'll include questions to answer and practical methods to ensure a thorough guide!
codex
Here’s a practical end-to-end process you can use to price a new product (works for SaaS, APIs, and most B2B/B2C software).

1) Define the pricing “job”
- Goal: maximize revenue, adoption, profit, or speed-to-market (pick one primary).
- Constraints: brand positioning (premium vs value), sales motion (self-serve vs sales-led), contract norms, regulatory/market limits.
- Success metrics: conversion rate, ARPA/ARPU, retention, gross margin, CAC payback.

2) Pin down who you’re pricing for (segmentation)
- Identify 2–4 core segments that differ in willingness-to-pay (WTP) and usage (e.g., SMB vs mid-market; hobbyist vs pro).
- Write a simple segment table: segment, main use case, value drivers, budget owner, alternatives, expected usage range.

3) Define what customers are actually paying for (value metric)
Pick the “meter” that best tracks value and scales with customer outcomes:
- Subscription: per seat, per workspace, per location.
- Usage-based: per API call, per GB, per transaction, per automations run.
- Hybrid: base subscription + usage overages.
Rules of thumb:
- The metric should be understandable, controllable by the buyer, and correlate with value.
- Avoid metrics that spike unpredictably unless you add caps/commitments.

4) Quantify value and anchor ranges (value-based pricing)
- Estimate economic value: time saved, revenue gained, risk reduced, cost avoided.
- Convert to an ROI story: “We create ~$X/month of value; price captures ~10–30% of that” (common in B2B, varies widely).
- Output: a believable WTP range per segment (not a single number yet).

5) Do market reality checks (competition + alternatives)
- Map alternatives (including “do nothing” and internal tools), not just direct competitors.
- Note price model, packaging, and the “gotchas” (limits, overages, required add-ons).
- Decide your positioning: cheaper, parity, or premium—and why you win.

6) Build your floors: unit economics and deal economics
You need a hard floor to avoid pricing that can’t work:
- Variable costs (COGS): infra, support, onboarding, compliance, third-party fees.
- Gross margin target (common SaaS: high; usage-heavy products: lower but still planned).
- Sales costs: if sales-led, ensure ACV supports CAC payback targets.
- Output: minimum viable price (by segment/model) and minimum contract size if applicable.

7) Design packaging (tiers) before picking the final numbers
- Create 3 tiers that match segments/use cases (e.g., Starter / Pro / Enterprise).
- Differentiate tiers by: limits, features, compliance, admin controls, SLA, support, integrations.
- Make upgrades feel natural as value/complexity grows; avoid “random” feature gating.

8) Set initial price points (list price, not just “what we’ll discount to”)
A simple way to land on numbers:
- Choose an “intended” tier for your core segment (the one most should buy).
- Price it inside your WTP range and above your economic floor.
- Use price architecture to guide choices:
  - 3 tiers with ~2–3× jumps (Starter → Pro → Enterprise) is common.
  - Ensure Starter is viable but intentionally constrained (to prevent over-delivery).
- Decide discount policy early (annual prepay, volume, startups, nonprofit) and set guardrails.

9) Validate with lightweight research + tests (before locking in)
Combine qualitative + quantitative:
- Pricing interviews (10–20): test value metric, packaging clarity, and “would you buy at $X?” with context.
- Van Westendorp (good for simpler B2C/self-serve): “too cheap/cheap/expensive/too expensive.”
- Gabor-Granger (good for B2B): present price points and measure purchase intent.
- Offer tests (best if you can): landing page A/B, checkout experiments, sales quoting experiments.
Output: where resistance appears (metric confusion, tier mismatch, price too high/low) and updated ranges.

10) Launch with guardrails and a plan to iterate
- Publish pricing with clear limits, examples, and a calculator (especially for usage-based).
- Add protections: free trial design, caps/alerts, grace thresholds, annual commit options.
- Set review cadence (e.g., monthly for early stage) and watch:
  - Conversion by segment, expansion, churn, gross margin, discounting behavior, support load.
- Iterate carefully: packaging changes often outperform pure price changes.

If you tell me (a) B2B vs B2C, (b) sales-led vs self-serve, (c) what the product replaces, and (d) your likely value metric, I can help you produce a first-pass tier/package + price range and a concrete validation plan.
tokens used
2,189
```


### scenario

Prompt:

```
We're launching a new tier of our SaaS product. Leadership wants to price it at $99/month but I think that's too low. How do I validate willingness to pay before we launch?
```

Response:

```
Validate willingness to pay with evidence that gets as close to “real money” as possible, not opinions.

- **Start with segmentation + value**: Define 2–3 target segments and the specific outcomes this $99 tier delivers (otherwise WTP data is noisy).
- **Run “price-fence” interviews (5–10/segment)**: Show the tier, ask for the last time they paid for similar value, then probe **budget owner, purchase process, alternatives**, and **what would make it a “must have”**. Avoid “Would you pay $99?”; instead ask “At what price does this become a no-brainer / expensive but worth it / too expensive?”
- **Do a structured WTP survey (fast signal)**: Use **Van Westendorp** (good for bounds) or **Gabor–Granger** (good for take-rate curve). Include competitor/alternative spend to anchor in reality; analyze by segment.
- **Run a landing-page/checkout experiment (best pre-launch signal)**: Drive your target traffic to a page with the tier and randomly show prices (e.g., $99/$129/$159). Measure **click-to-start-checkout, checkout completion, sales call requests**. Even better: collect a **deposit or paid pilot**.
- **Offer paid pilots or annual prepay**: “Lock in early access at $X/month (annual upfront)” is a strong revealed-preference test; track acceptance rate and objections at each price.
- **Decide with a curve, not a single number**: Pick the price that maximizes your objective (revenue, gross margin, payback, adoption), and document the tradeoff (e.g., $99 yields +20% adoption but -30% revenue vs $149).

If you tell me your target customer, core value metric, and who approves spend, I can suggest a concrete experiment design (prices, sample size, and the exact questions/script).

[stderr]
OpenAI Codex v0.80.0 (research preview)
--------
workdir: /Users/davidturner/Code/Playground/ProductSkills
model: gpt-5.2
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019bc21a-2704-7222-92b5-f6cd41babf4a
--------
user
We're launching a new tier of our SaaS product. Leadership wants to price it at $99/month but I think that's too low. How do I validate willingness to pay before we launch?
mcp startup: no servers

thinking
**Formulating a product strategy**

The user is asking for a product strategy that doesn't involve coding or technical skills. My plan is to provide a concise approach to validating willingness to pay (WTP) through methods like Van Westendorp and Gabor-Granger analysis, conjoint studies, interviews, landing page tests, and more. I'll focus on avoiding hypotheticals and emphasize using revealed preferences. I need to outline clear steps, sample scripts, key metrics, and ethical considerations while keeping everything within ten lines.
codex
Validate willingness to pay with evidence that gets as close to “real money” as possible, not opinions.

- **Start with segmentation + value**: Define 2–3 target segments and the specific outcomes this $99 tier delivers (otherwise WTP data is noisy).
- **Run “price-fence” interviews (5–10/segment)**: Show the tier, ask for the last time they paid for similar value, then probe **budget owner, purchase process, alternatives**, and **what would make it a “must have”**. Avoid “Would you pay $99?”; instead ask “At what price does this become a no-brainer / expensive but worth it / too expensive?”
- **Do a structured WTP survey (fast signal)**: Use **Van Westendorp** (good for bounds) or **Gabor–Granger** (good for take-rate curve). Include competitor/alternative spend to anchor in reality; analyze by segment.
- **Run a landing-page/checkout experiment (best pre-launch signal)**: Drive your target traffic to a page with the tier and randomly show prices (e.g., $99/$129/$159). Measure **click-to-start-checkout, checkout completion, sales call requests**. Even better: collect a **deposit or paid pilot**.
- **Offer paid pilots or annual prepay**: “Lock in early access at $X/month (annual upfront)” is a strong revealed-preference test; track acceptance rate and objections at each price.
- **Decide with a curve, not a single number**: Pick the price that maximizes your objective (revenue, gross margin, payback, adoption), and document the tradeoff (e.g., $99 yields +20% adoption but -30% revenue vs $149).

If you tell me your target customer, core value metric, and who approves spend, I can suggest a concrete experiment design (prices, sample size, and the exact questions/script).
tokens used
1,406
```


### application

Prompt:

```
Apply the Monetizing Innovation framework to our API product. We're not sure if we should charge per seat, per API call, or flat rate. How do I think through this?
```

Response:

```
Monetizing Innovation’s core move is: stop debating *pricing models* first (seat/call/flat) and instead pick a *value metric* that tracks customers’ willingness to pay (WTP), then package and price around it.

**1) Start with value (not costs)**
- Define the “must-have” outcome your API enables (time saved, revenue gained, risk reduced, compliance met, churn reduced).
- Quantify the economic value for 2–3 target segments (SMB, mid-market, enterprise; or by use case). Your goal is a rough value range per month/year per segment.

**2) Find the right value metric (the framework’s key step)**
A good value metric is:
- Highly correlated with value realized
- Predictable and controllable for the buyer (no “bill shock”)
- Easy to measure and explain
- Scales as customers succeed (you win when they win)
- Doesn’t punish adoption/experimentation early

**3) Evaluate your three options through that lens**
- Per API call
  - Best when value scales tightly with volume and customers can forecast usage (e.g., enrichment/lookups).
  - Risks: customers optimize away usage, fear of variable bills, slows onboarding (“don’t call it too much yet”).
- Per seat
  - Best when the product’s value is created by human users operating it (workflows, dashboards, approvals).
  - For pure APIs it’s usually misaligned (a 2-person team can drive massive value/usage; seat becomes arbitrary and hard to justify).
- Flat rate
  - Best when value is relatively fixed and customers demand budget certainty (enterprise procurement, critical infrastructure).
  - Risks: underpricing high-value/high-volume customers or overpricing small ones; you’ll need strong packaging “fences” to avoid one plan fitting everyone.

**4) What Monetizing Innovation usually recommends for APIs: a hybrid value metric**
For many API products, the most durable approach is:
- A base subscription (anchors budget + funds reliability/support/SLA) **plus**
- Usage tiers or overages tied to the value driver (often calls, but sometimes a better proxy like “records processed”, “active end-users served”, “transactions”, “files analyzed”, “successful validations”, etc.)

This keeps the model fair (pay more as you get more value) without scaring buyers with purely variable pricing.

**5) Pressure-test with 5 customer questions (fast)**
Ask prospects/customers:
- “What would you *replace* this with and what does that cost today?”
- “What’s the business outcome you’d tie this to (revenue, time, risk)?”
- “Which metric feels fairest: calls, transactions, records, end-users, sites, or something else—and why?”
- “What level of bill variability is acceptable month-to-month?”
- “At what point would pricing feel ‘punitive’ and change behavior?”

**6) Decide packaging + fences (so one metric doesn’t fit all)**
Create 3–4 tiers (Good/Better/Best) with fences like:
- Included usage, then overage
- SLA/support levels
- Compliance/security features
- Rate limits, environments, retention, or advanced capabilities

If you tell me (a) the primary outcome your API enables, (b) who uses it (developers only vs ops/business users too), and (c) what scales value (calls, transactions, records, end-users), I can recommend a specific value metric and a concrete tier + price architecture to test.

[stderr]
OpenAI Codex v0.80.0 (research preview)
--------
workdir: /Users/davidturner/Code/Playground/ProductSkills
model: gpt-5.2
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019bc21a-557f-7d71-894f-e01a6fd5d8b0
--------
user
Apply the Monetizing Innovation framework to our API product. We're not sure if we should charge per seat, per API call, or flat rate. How do I think through this?
mcp startup: no servers


thinking
**Evaluating pricing structures**

I'm thinking about the decision matrix for different pricing options. There are pros and cons to each: per call can scale but may lead to unpredictability; per seat values individual users but doesn't fit APIs well; flat fees are good for budget predictability but may limit scaling. Hybrids combine a base fee with overage charges.

I wonder if subscription tiers could work, with included calls and overages, or based on customer revenue, and metrics around "active end-users." It’s essential to avoid charging for unvalued features too!
thinking
**Explaining monetization strategy**

I'm thinking about applying the MI approach: first, identify the value instead of focusing on cost; then quantify the willingness to pay (WTP). Next, I’ll select a value metric and validate it through customer interviews. After that, designing packaging and price fences will be essential. 

For metric selection, I want to compare seat, call, and flat rates. A recommended default for the API could be a subscription model with usage tiers that includes calls, plus overage, and possibly seat-based options for admin tools. I should also mention the importance of a harmonized price metric and a solid monetization architecture!
codex
Monetizing Innovation’s core move is: stop debating *pricing models* first (seat/call/flat) and instead pick a *value metric* that tracks customers’ willingness to pay (WTP), then package and price around it.

**1) Start with value (not costs)**
- Define the “must-have” outcome your API enables (time saved, revenue gained, risk reduced, compliance met, churn reduced).
- Quantify the economic value for 2–3 target segments (SMB, mid-market, enterprise; or by use case). Your goal is a rough value range per month/year per segment.

**2) Find the right value metric (the framework’s key step)**
A good value metric is:
- Highly correlated with value realized
- Predictable and controllable for the buyer (no “bill shock”)
- Easy to measure and explain
- Scales as customers succeed (you win when they win)
- Doesn’t punish adoption/experimentation early

**3) Evaluate your three options through that lens**
- Per API call
  - Best when value scales tightly with volume and customers can forecast usage (e.g., enrichment/lookups).
  - Risks: customers optimize away usage, fear of variable bills, slows onboarding (“don’t call it too much yet”).
- Per seat
  - Best when the product’s value is created by human users operating it (workflows, dashboards, approvals).
  - For pure APIs it’s usually misaligned (a 2-person team can drive massive value/usage; seat becomes arbitrary and hard to justify).
- Flat rate
  - Best when value is relatively fixed and customers demand budget certainty (enterprise procurement, critical infrastructure).
  - Risks: underpricing high-value/high-volume customers or overpricing small ones; you’ll need strong packaging “fences” to avoid one plan fitting everyone.

**4) What Monetizing Innovation usually recommends for APIs: a hybrid value metric**
For many API products, the most durable approach is:
- A base subscription (anchors budget + funds reliability/support/SLA) **plus**
- Usage tiers or overages tied to the value driver (often calls, but sometimes a better proxy like “records processed”, “active end-users served”, “transactions”, “files analyzed”, “successful validations”, etc.)

This keeps the model fair (pay more as you get more value) without scaring buyers with purely variable pricing.

**5) Pressure-test with 5 customer questions (fast)**
Ask prospects/customers:
- “What would you *replace* this with and what does that cost today?”
- “What’s the business outcome you’d tie this to (revenue, time, risk)?”
- “Which metric feels fairest: calls, transactions, records, end-users, sites, or something else—and why?”
- “What level of bill variability is acceptable month-to-month?”
- “At what point would pricing feel ‘punitive’ and change behavior?”

**6) Decide packaging + fences (so one metric doesn’t fit all)**
Create 3–4 tiers (Good/Better/Best) with fences like:
- Included usage, then overage
- SLA/support levels
- Compliance/security features
- Rate limits, environments, retention, or advanced capabilities

If you tell me (a) the primary outcome your API enables, (b) who uses it (developers only vs ops/business users too), and (c) what scales value (calls, transactions, records, end-users), I can recommend a specific value metric and a concrete tier + price architecture to test.
tokens used
1,828
```


