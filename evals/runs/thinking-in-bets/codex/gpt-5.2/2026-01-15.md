# Skill Eval Feedback

skill: thinking-in-bets
agent: codex
model: gpt-5.2
date: 2026-01-15
prompt-set: evals/prompts/skill-prompts.yaml

## Prompt Results

| Prompt ID | Triggered? | Helpful? (1-5) | Too Much Context? | Missing Context? | Notes |
|-----------|------------|----------------|-------------------|------------------|-------|
| minimal |  |  |  |  |  |
| context |  |  |  |  |  |

## Overall

- Trigger quality:
- Usefulness:
- Over/under-trigger risk:
- Suggested description tweaks:
- Suggested SKILL.md tweaks:

## Raw Output

### minimal

Prompt:

```
How do I make better decisions under uncertainty? Explain thinking in bets.
```

Response:

```
Thinking in bets (from poker, popularized by Annie Duke) is a way to make decisions when you can’t know the outcome in advance: you judge decisions by the quality of the process and the odds you accepted, not by whether you “won” this time.

**Core idea**
- Every decision is a bet: you choose an action under uncertainty with some probability of different outcomes.
- Good decisions can lead to bad outcomes (bad luck). Bad decisions can lead to good outcomes (good luck).
- Your job is to make bets with positive expected value, size them appropriately, and update as you learn.

**How to apply it**
- **Separate decision quality from outcome**: After results come in, ask “Was my reasoning good given what I knew then?” not “Did it work?”
- **Use probabilities, not certainty words**: Replace “will” with “I’m ~70% confident.” This makes your beliefs testable and updatable.
- **Start from base rates**: Before you dive into specifics, ask “For similar situations, how often does this work?” Then adjust for what’s truly different.
- **Think in expected value (EV)**: Roughly: `EV = (probability of outcome) × (value of outcome)`, summed across outcomes. Prefer actions with better EV, not just best-case.
- **Size the bet**: When uncertain, reduce commitment (smaller rollout, reversible choice, staged investment). When confident and upside is large, commit more.
- **Plan to learn (information value)**: Sometimes the best bet is the one that gives you fast feedback (cheap experiment) even if short-term EV is slightly lower.
- **Update beliefs deliberately**: When new evidence arrives, adjust your probabilities. Don’t “double down” just to be consistent.

**Practical tools**
- **Decision journal (before you know the outcome)**: Write
  - the choice you’re making,
  - your top 2–3 reasons,
  - key assumptions,
  - your probability estimate(s),
  - what would change your mind.
- **Pre-mortem**: “It’s 6 months later and this failed—why?” Convert the top reasons into risk mitigations or tests.
- **Post-mortem with luck check**: For outcomes, classify: good decision/good outcome, good decision/bad outcome, etc. Focus improvement on “bad decision” cases.
- **Calibration practice**: Track your 60–70–80% calls; over time, your “70%” should be right about 70% of the time.

**A simple example**
- “Should we launch feature X now?”
  - Base rate: similar launches succeeded 60% of the time.
  - You estimate: 65% chance it increases retention, 25% neutral, 10% harms.
  - Instead of all-or-nothing, you bet smaller: staged rollout + guardrails (metrics, rollback plan). You preserve upside while capping downside.

If you tell me what kind of decisions you mean (career, product, investing, relationships), I can translate “thinking in bets” into a concrete checklist and a couple of templates for that context.

[stderr]
OpenAI Codex v0.80.0 (research preview)
--------
workdir: /Users/davidturner/Code/Playground/ProductSkills
model: gpt-5.2
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019bc226-c05a-7612-bc69-7d1213c63beb
--------
user
How do I make better decisions under uncertainty? Explain thinking in bets.
mcp startup: no servers

thinking
**Explaining "Thinking in Bets"**

The user is asking for advice on the "Thinking in Bets" concept, no coding necessary. I’ll provide a concise explanation focusing on key ideas like separating outcomes from decision quality, using probabilistic thinking, calibrating expected value, recognizing base rates, updating beliefs, and employing techniques like decision journals and premortems. I want to include practical exercises without being overly lengthy or complicated. Mentioning Annie Duke will be relevant for context, and I'll structure this clearly for clarity.
codex
Thinking in bets (from poker, popularized by Annie Duke) is a way to make decisions when you can’t know the outcome in advance: you judge decisions by the quality of the process and the odds you accepted, not by whether you “won” this time.

**Core idea**
- Every decision is a bet: you choose an action under uncertainty with some probability of different outcomes.
- Good decisions can lead to bad outcomes (bad luck). Bad decisions can lead to good outcomes (good luck).
- Your job is to make bets with positive expected value, size them appropriately, and update as you learn.

**How to apply it**
- **Separate decision quality from outcome**: After results come in, ask “Was my reasoning good given what I knew then?” not “Did it work?”
- **Use probabilities, not certainty words**: Replace “will” with “I’m ~70% confident.” This makes your beliefs testable and updatable.
- **Start from base rates**: Before you dive into specifics, ask “For similar situations, how often does this work?” Then adjust for what’s truly different.
- **Think in expected value (EV)**: Roughly: `EV = (probability of outcome) × (value of outcome)`, summed across outcomes. Prefer actions with better EV, not just best-case.
- **Size the bet**: When uncertain, reduce commitment (smaller rollout, reversible choice, staged investment). When confident and upside is large, commit more.
- **Plan to learn (information value)**: Sometimes the best bet is the one that gives you fast feedback (cheap experiment) even if short-term EV is slightly lower.
- **Update beliefs deliberately**: When new evidence arrives, adjust your probabilities. Don’t “double down” just to be consistent.

**Practical tools**
- **Decision journal (before you know the outcome)**: Write
  - the choice you’re making,
  - your top 2–3 reasons,
  - key assumptions,
  - your probability estimate(s),
  - what would change your mind.
- **Pre-mortem**: “It’s 6 months later and this failed—why?” Convert the top reasons into risk mitigations or tests.
- **Post-mortem with luck check**: For outcomes, classify: good decision/good outcome, good decision/bad outcome, etc. Focus improvement on “bad decision” cases.
- **Calibration practice**: Track your 60–70–80% calls; over time, your “70%” should be right about 70% of the time.

**A simple example**
- “Should we launch feature X now?”
  - Base rate: similar launches succeeded 60% of the time.
  - You estimate: 65% chance it increases retention, 25% neutral, 10% harms.
  - Instead of all-or-nothing, you bet smaller: staged rollout + guardrails (metrics, rollback plan). You preserve upside while capping downside.

If you tell me what kind of decisions you mean (career, product, investing, relationships), I can translate “thinking in bets” into a concrete checklist and a couple of templates for that context.
tokens used
1,386
```


### scenario

Prompt:

```
We have two major product bets we could make but can only resource one. Both have uncertain outcomes. How do I think through this decision without just going with my gut?
```

Response:

```
Don’t try to pick the “right” bet—pick the bet with the best *risk‑adjusted expected value* given what you can learn quickly.

- **Write a 1‑pager for each bet (forces clarity):** target user, problem, proposed solution, why now, how it wins (distribution + differentiation), what “success in 6–12 months” means (1–2 measurable metrics).
- **Model outcomes, not narratives:** for each bet, define 3–4 scenarios (e.g., fail / modest / strong / breakout), assign rough probabilities, and estimate value if it hits (revenue, retention, strategic value). Compute a simple expected value: `Σ(probability × value)`.
- **Surface the *critical uncertainties*:** list assumptions and mark which ones are both (a) most likely wrong and (b) most damaging if wrong (usually: willingness to pay, frequency/severity, reachability via a channel, time-to-value).
- **Compare by “time to truth”:** for each bet, ask “What’s the cheapest experiment that could change our probability by a lot in 2–4 weeks?” Prefer the bet with higher upside *and* faster/cheaper uncertainty reduction.
- **Account for option value and cost of delay:** which bet gets harder if you wait (competitive window, platform shifts, data/learning compounding)? Which one is more reversible if wrong?
- **Run a premortem + kill criteria:** write “It’s 6 months later and this failed because…” then set explicit stop/continue thresholds now (so you’re not relying on gut later).
- **Decide and document:** record the probabilities, assumptions, experiment plan, and what evidence would make you switch—this turns “gut” into an auditable decision.

If you share one paragraph describing each bet (who it’s for + what changes for the user + how you’d ship it), I can help you draft the scenario table and identify the 2–3 highest‑leverage tests.

[stderr]
OpenAI Codex v0.80.0 (research preview)
--------
workdir: /Users/davidturner/Code/Playground/ProductSkills
model: gpt-5.2
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019bc227-05f9-7570-a848-e83ceb207cbe
--------
user
We have two major product bets we could make but can only resource one. Both have uncertain outcomes. How do I think through this decision without just going with my gut?
mcp startup: no servers

thinking
**Structuring decision-making**

I'm outlining a concrete process to tackle decision-making effectively. First, I need to define objectives and success metrics. Then, I'll create a one-pager for specified bets and quantify their upside, downside, and probabilities. 

Next, it's important to identify critical assumptions and evaluate the expected value of information. I'll run sanity checks and decide based on gathered data while documenting everything. Ultimately, I'll craft a decision tree with various scenarios to compute expected outcomes and include tie-breakers. Lastly, my immediate action will be to create an "assumption map" and set a two-week spike.
codex
Don’t try to pick the “right” bet—pick the bet with the best *risk‑adjusted expected value* given what you can learn quickly.

- **Write a 1‑pager for each bet (forces clarity):** target user, problem, proposed solution, why now, how it wins (distribution + differentiation), what “success in 6–12 months” means (1–2 measurable metrics).
- **Model outcomes, not narratives:** for each bet, define 3–4 scenarios (e.g., fail / modest / strong / breakout), assign rough probabilities, and estimate value if it hits (revenue, retention, strategic value). Compute a simple expected value: `Σ(probability × value)`.
- **Surface the *critical uncertainties*:** list assumptions and mark which ones are both (a) most likely wrong and (b) most damaging if wrong (usually: willingness to pay, frequency/severity, reachability via a channel, time-to-value).
- **Compare by “time to truth”:** for each bet, ask “What’s the cheapest experiment that could change our probability by a lot in 2–4 weeks?” Prefer the bet with higher upside *and* faster/cheaper uncertainty reduction.
- **Account for option value and cost of delay:** which bet gets harder if you wait (competitive window, platform shifts, data/learning compounding)? Which one is more reversible if wrong?
- **Run a premortem + kill criteria:** write “It’s 6 months later and this failed because…” then set explicit stop/continue thresholds now (so you’re not relying on gut later).
- **Decide and document:** record the probabilities, assumptions, experiment plan, and what evidence would make you switch—this turns “gut” into an auditable decision.

If you share one paragraph describing each bet (who it’s for + what changes for the user + how you’d ship it), I can help you draft the scenario table and identify the 2–3 highest‑leverage tests.
tokens used
1,698
```


### application

Prompt:

```
Help me apply thinking in bets to a launch decision. We can either launch a smaller feature now (70% confident it helps) or wait 2 months for the bigger version (40% confident). How do I evaluate this?
```

Response:

```
Treat it like a bet with (1) an expected payoff, (2) a time component, and (3) option value from learning.

1) Define payoffs in the same units  
- Pick a horizon (e.g., next 12 months) and a unit (e.g., incremental $/month, WAU, retention points).  
- For each option, write outcomes and *include downside*, not just “helps / doesn’t help” (e.g., helps, neutral, hurts).

2) Compute time-adjusted expected value (EV)  
If benefit is roughly linear per month and your horizon is `H` months:
- Smaller now: `EV_small ≈ 0.7 * (Benefit_small_per_month * H) + 0.3 * (Downside_small_per_month * H) - Cost_small`
- Bigger in 2 months: `EV_big ≈ 0.4 * (Benefit_big_per_month * (H-2)) + 0.6 * (Downside_big_per_month * (H-2)) - Cost_big`  
This makes the opportunity cost of waiting explicit (you only get `(H-2)` months of upside, plus you risk learning nothing for 2 months).

3) Add “Thinking in Bets” option value (sequential decision)  
Often the real comparison isn’t “small now OR big later”, it’s:
- Ship small now → observe results → decide whether to build big, pivot, or stop.  
Model it as a decision tree:
- `EV_ship_small_now = EV_small_now + P(success_signal)*EV_build_big_given_signal + P(bad_signal)*EV_stop_or_redesign`  
If shipping small meaningfully reduces uncertainty (raises the 40% later, or helps you avoid a bad build), that learning value can dominate.

4) Sanity-check the probabilities (calibration)  
Make the 70% and 40% defensible:
- What would you expect to see if it *does* help? If it *doesn’t*?  
- What base rate are you using (similar launches)? What evidence moved you off the base rate?

5) Risk/regret filter (“can we survive the losing outcomes?”)  
Even if EV favors “ship now”, don’t take a bet with unacceptable downside:
- What’s the worst-case if it hurts (trust, churn, support load, brand)?  
- Can you limit exposure (beta, feature flag, gradual rollout, kill switch, reversibility)?

If you tell me (a) expected upside size for small vs big, (b) worst-case downside, (c) whether you can still build the big version after shipping small, and (d) your time horizon, I can help you fill in a simple EV + decision-tree calculation with your numbers.

[stderr]
OpenAI Codex v0.80.0 (research preview)
--------
workdir: /Users/davidturner/Code/Playground/ProductSkills
model: gpt-5.2
provider: openai
approval: never
sandbox: workspace-write [workdir, /tmp, $TMPDIR]
reasoning effort: high
reasoning summaries: auto
session id: 019bc227-47fc-79c1-992f-186e7bc1338d
--------
user
Help me apply thinking in bets to a launch decision. We can either launch a smaller feature now (70% confident it helps) or wait 2 months for the bigger version (40% confident). How do I evaluate this?
mcp startup: no servers

Reconnecting... 1/5 (stream disconnected before completion: Transport error: network error: error decoding response body)




thinking
**Exploring decision strategies**

The user is seeking advice on applying "thinking in bets" for making decisions. I want to outline a helpful framework, including concepts like expected value, opportunity cost, and learning value. I should give steps that define outcomes, identify payoff sizes, and create a decision tree to analyze incremental effects. It's essential to compare expected value with time and learning considerations. Additionally, I’ll provide examples with placeholders for key metrics while calculating potential outcomes.
thinking
**Applying thinking principles**

I’m looking to provide key "Thinking in Bets" principles to help the user separate decision quality from outcomes. I'll include techniques like mapping uncertainties, backcasting, and using premortems. A simple template will help keep it concise yet practical. I want to incorporate a numeric example and ask the user for missing inputs, such as the magnitude of impact and potential downsides. The steps will include defining the objective, listing options, assigning scenarios and payoffs, and ultimately computing expected value.
thinking
**Calculating expected values**

I’m working on calculating the expected value for both small and big options. For the big option, I want to consider factors like a 2-month delay, risk, and possible negative payoffs. Using bet sizing is essential to choose the option with a higher expected value while allowing for acceptable worst-case scenarios. I’ll create a simple example. If a small option yields a $100k monthly benefit, I’ll calculate its expected value, and then for the big option, I'll consider benefits over the next 12 months, including net present value adjustments.
thinking
**Structuring expected value calculations**

I’m calculating the expected values for both small and big options. For the small option, it’s EV_small = 0.7*B_small*12 - C_small, while for the big option, it's EV_big = 0.4*B_big*10 - C_big. I want to compare these values, and also consider a combined approach where I ship the small option now and keep building the big one. This might change the probabilities. I’ll include prompts for the user to fill and highlight the importance of evidence in assessing confidence levels. Let’s finalize this structure!
codex
Treat it like a bet with (1) an expected payoff, (2) a time component, and (3) option value from learning.

1) Define payoffs in the same units  
- Pick a horizon (e.g., next 12 months) and a unit (e.g., incremental $/month, WAU, retention points).  
- For each option, write outcomes and *include downside*, not just “helps / doesn’t help” (e.g., helps, neutral, hurts).

2) Compute time-adjusted expected value (EV)  
If benefit is roughly linear per month and your horizon is `H` months:
- Smaller now: `EV_small ≈ 0.7 * (Benefit_small_per_month * H) + 0.3 * (Downside_small_per_month * H) - Cost_small`
- Bigger in 2 months: `EV_big ≈ 0.4 * (Benefit_big_per_month * (H-2)) + 0.6 * (Downside_big_per_month * (H-2)) - Cost_big`  
This makes the opportunity cost of waiting explicit (you only get `(H-2)` months of upside, plus you risk learning nothing for 2 months).

3) Add “Thinking in Bets” option value (sequential decision)  
Often the real comparison isn’t “small now OR big later”, it’s:
- Ship small now → observe results → decide whether to build big, pivot, or stop.  
Model it as a decision tree:
- `EV_ship_small_now = EV_small_now + P(success_signal)*EV_build_big_given_signal + P(bad_signal)*EV_stop_or_redesign`  
If shipping small meaningfully reduces uncertainty (raises the 40% later, or helps you avoid a bad build), that learning value can dominate.

4) Sanity-check the probabilities (calibration)  
Make the 70% and 40% defensible:
- What would you expect to see if it *does* help? If it *doesn’t*?  
- What base rate are you using (similar launches)? What evidence moved you off the base rate?

5) Risk/regret filter (“can we survive the losing outcomes?”)  
Even if EV favors “ship now”, don’t take a bet with unacceptable downside:
- What’s the worst-case if it hurts (trust, churn, support load, brand)?  
- Can you limit exposure (beta, feature flag, gradual rollout, kill switch, reversibility)?

If you tell me (a) expected upside size for small vs big, (b) worst-case downside, (c) whether you can still build the big version after shipping small, and (d) your time horizon, I can help you fill in a simple EV + decision-tree calculation with your numbers.
tokens used
2,282
```


