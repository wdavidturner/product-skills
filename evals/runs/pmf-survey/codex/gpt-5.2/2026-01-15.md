# Skill Eval Feedback

skill: pmf-survey
agent: codex
model: gpt-5.2
date: 2026-01-15
prompt-set: evals/prompts/skill-prompts.yaml

## Prompt Results

| Prompt ID | Triggered? | Helpful? (1-5) | Too Much Context? | Missing Context? | Notes |
|-----------|------------|----------------|-------------------|------------------|-------|
| minimal |  |  |  |  |  |
| context |  |  |  |  |  |

## Overall

- Trigger quality:
- Usefulness:
- Over/under-trigger risk:
- Suggested description tweaks:
- Suggested SKILL.md tweaks:

## Raw Output

### minimal

Prompt:

```
How do I measure product-market fit? What's the PMF survey and how do I use it?
```

Response:

```
Product–market fit (PMF) is when a specific market segment consistently gets clear value from your product such that demand is repeatable (retention and/or revenue grows without heroic selling).

**How to measure PMF (practical signals)**
- **Retention cohorts**: do users keep using it after first value (weeks/months)? Look for a flattening “tail,” not a steady slide to zero.
- **Activation → habit loop**: what % reach the “aha” moment and repeat the key action?
- **Willingness to pay**: pricing acceptance, conversion to paid, expansion, low churn (or shortening sales cycles in B2B).
- **Pull vs. push**: organic inbound, referrals/word-of-mouth, users complaining when it’s down, clear “must-have” use cases.

**The PMF survey (Sean Ellis)**
- Core question: “**How would you feel if you could no longer use [product]?**”
  - **Very disappointed**
  - Somewhat disappointed
  - Not disappointed (or N/A)
- Heuristic: if **≥ 40%** of the right users say **“Very disappointed,”** you likely have PMF *in that segment*.

**How to use it well**
- Survey **only users who have experienced value** (e.g., activated + used key feature X times), and **segment** results by persona/use case/source.
- Add 2–3 follow-ups:
  - “What’s the **main benefit** you receive?”
  - “What type of people do you think this is **best for**?”
  - “What’s the **one thing** we could improve?”
- Analyze “very disappointed” users: extract the repeated value statements, identify the strongest segment, then **focus roadmap + messaging + acquisition** around that use case and re-run periodically.

If you tell me your product type (B2B/B2C), target user, and what “activation” looks like, I can suggest a concrete survey audience filter and sample size.
```


### scenario

Prompt:

```
Investors keep asking if we have product-market fit. Some users love us, others churn immediately. I need a concrete way to measure where we are and track progress.
```

Response:

```
Measure PMF as a repeatable “love + retention + willingness-to-pay” scorecard, sliced by user segment (because your “love vs churn” usually means you have PMF in *one* segment and not others).

- **Define the core use case + segment**: pick 1 “who + job” (e.g., “solo PMs tracking X weekly”) and 1 **core action** that represents value (your “aha” event).
- **Activation (leading indicator)**: `% of new users who complete core action within T days` + **median time-to-first-value** (TTFV). Track by acquisition channel + segment.
- **Retention (PMF backbone)**: cohort chart of **active retention** (not logins) at D7/D30 (B2C) or W4/W8 (B2B). PMF shows up as a retention curve that flattens to a stable floor for the right segment.
- **Depth of use**: frequency of core action among retained users (e.g., core actions/user/week, WAU/MAU, or “% weeks with ≥1 core action”).
- **Willingness-to-pay / pull**: trial→paid conversion (if applicable), expansion/seat growth, and “% who tried to solve this elsewhere” (switching/pain signals).
- **PMF survey (simple, investor-friendly)**: monthly Sean Ellis survey to *active* users: “How disappointed if you could no longer use this?” Track `% Very disappointed` (a common benchmark is ~40%+), and always break results by segment + “reason for disappointment”.

If you tell me whether you’re B2B or B2C and what your “core action” is today, I’ll map this into a 1-page dashboard (exact metrics + time windows) you can report every month.
```


### application

Prompt:

```
Help me run a PMF survey. We have 500 active users. What question do I ask, how do I interpret the results, and what's a good benchmark?
```

Response:

```
Ask the Sean Ellis PMF question:

- “How would you feel if you could no longer use *[Product]*?”
  - Very disappointed
  - Somewhat disappointed
  - Not disappointed
  - (Optional) N/A — I no longer use it / haven’t used it enough

Add 2–3 follow-ups (open text) to make the result actionable:
- “What is the main benefit you receive from *[Product]*?”
- “What type of people would most benefit from *[Product]*?”
- “What is the main reason you chose your answer?” (or “What could we do to make it a must-have?” for “somewhat”)

How to interpret:
- Your PMF score = `% “Very disappointed”` among the *right population* (typically: users who have experienced the core value; exclude “N/A / haven’t used enough”).
- Segment the score (this is where the insight usually is): by use case, role, company size, tenure/cohort, frequency, and “activated” vs not. If one segment is high but the overall is low, you likely have PMF in a niche—focus there.
- Use the follow-ups to extract:
  - The “must-have” value prop (themes from “very disappointed”)
  - The missing pieces (themes from “somewhat disappointed”)
  - Who the product is *actually* for (the “type of people” answers)

Benchmark:
- Classic benchmark: **40%+ “Very disappointed”** = strong signal of PMF (in the properly-targeted segment).
- Rules of thumb:
  - **<25%**: weak PMF signal (positioning/value not landing, or surveying too broad an audience)
  - **25–40%**: early/partial PMF (often strong in a subsegment)
  - **>50%**: very strong pull

Practical notes for your 500 active users:
- You can survey all 500, but ensure it goes to *recently active* users and ideally those past activation; otherwise you’ll understate PMF.
- Aim for a clean response rate (even ~150–250 responses can be directionally solid); analyze by segment before making big decisions.
```


